{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center\">The Perceptron</h1>\n",
    "<br><br> \n",
    "In this notebook, we will explore the Perceptron. A perceptron is one of the simplest machine learning models, and was designed to model a single biological neuron.\n",
    "<br><br> \n",
    "\n",
    "Inputs\n",
    "***\n",
    "<p>\n",
    "A neuron receives input signals from other neurons via its dendrites. In a perceptron, input signals are numeric values.\n",
    "</p>\n",
    "<br> <br>\n",
    "\n",
    "Weights\n",
    "***\n",
    "<p>\n",
    "A neuron assigns importance to its connections via the strength of the connections between neurons. In a perceptron, each input has a numerical weight.\n",
    "</p>\n",
    "<br> <br>\n",
    "\n",
    "Activation\n",
    "***\n",
    "<p>\n",
    "A neuron will fire and send an output signal if the input signals reach a certain threshold. In a perceptron, the output is determined by an activation function applied to the weighted sum of the inputs.\n",
    "</p>\n",
    "<br> <br>\n",
    "\n",
    "Output\n",
    "***\n",
    "A neuron's output is an action potential (rapid sequence of changes in voltage) that travels along the axon. In a perceptron, the output can be binary (0 or 1), or continuous depending on the activation function used.<br> <br>\n",
    "\n",
    "\n",
    "\n",
    "Through these components, a perceptron simplifies the complexity of a biological neuron. While simple, perceptrons form the foundation for neural networks. Subsequent advancements brought along more complex neural network architectures.\n",
    "<br> <br><br>\n",
    "\n",
    "How do we train perceptrons?\n",
    "***\n",
    "Perceptrons are trained using a learning algorithm called the **Perceptron Learning Rule**. Which consists of the following steps:\n",
    "1. Initialize weights to random values.\n",
    "2. Provide the training values (inputs of the input/output pairs)\n",
    "3. Compute output using the weighted sum, then the activation function.\n",
    "4. Update the weights using the perceptron learning rule: $w_i = w_i + \\Delta{w_i}$\n",
    "\n",
    "We compute $\\Delta{w_i}$ as follows: $$\\Delta{w_i}=\\alpha * (target - predicted) * x_i$$\n",
    "Where $\\alpha$ is a quantity called the learning rate, $target$ is the desired output for the given input, $predicted$ is the final output of step 3 and $x_i$ is the $i^{th}$ input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, learning_rate = 0.01, iterations = 50, random_number_seed = 1):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "        self.random_number_seed = random_number_seed\n",
    "    \n",
    "    def net_input(self, x):\n",
    "        return np.dot(x, self.w_i) + self.bias\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return np.where(self.net_input(x) >= 0.0, 1,0)\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        random_number_generator = np.random.RandomState(self.random_number_seed)\n",
    "\n",
    "        self.w_i = random_number_generator.normal(loc=0.0, scale=0.01, size=6)\n",
    "        self.bias = np.float_(0.)\n",
    "        self.errors = []\n",
    "\n",
    "        for i in range(0, self.iterations):\n",
    "            errors = 0\n",
    "            for x_i, target in zip(x,y):\n",
    "                update = self.learning_rate * (target - self.predict(x_i))\n",
    "                d_w = update * x_i\n",
    "                self.w_i += d_w\n",
    "                self.bias += update\n",
    "            self.errors.append(errors)\n",
    "        return self\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "test_linear_eq = Perceptron()\n",
    "\n",
    "X = np.array([1,2,3,4,5,6])\n",
    "Y = np.array([1,0,1,0,1,0])\n",
    "\n",
    "test_linear_eq.fit(X,Y)\n",
    "\n",
    "print(test_linear_eq.predict([1,2,3,4,5,6]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
